{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preliminary\n",
    "\n",
    "### 1.1 Context\n",
    "\n",
    "Vous travaillez pour la ville de Seattle. Pour atteindre son objectif de ville neutre en émissions de carbone en 2050, votre équipe s’intéresse de près à la consommation et aux émissions des bâtiments non destinés à l’habitation.\n",
    "\n",
    "Des relevés minutieux ont été effectués par les agents de la ville en 2016. Voici [les données](https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/Data_Scientist_P4/2016_Building_Energy_Benchmarking.csv) et [leur source](https://data.seattle.gov/dataset/2016-Building-Energy-Benchmarking/2bpz-gwpy). Cependant, ces relevés sont coûteux à obtenir, et à partir de ceux déjà réalisés, **vous voulez tenter de prédire les émissions de CO2 et la consommation totale d’énergie de bâtiments non destinés à l’habitation** pour lesquels elles n’ont pas encore été mesurées.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Votre prédiction se basera sur les données structurelles des bâtiments (taille et usage des bâtiments, date de construction, situation géographique, ...)\n",
    "</div>\n",
    "\n",
    "Vous cherchez également à **évaluer l’intérêt de l’\"[ENERGY STAR Score](https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/interpret-your-results/what)\" pour la prédiction d’émissions**, qui est fastidieux à calculer avec l’approche utilisée actuellement par votre équipe. Vous l'intégrerez dans la modélisation et jugerez de son intérêt.\n",
    "Vous sortez tout juste d’une réunion de brief avec votre équipe. Voici un récapitulatif de votre mission :\n",
    " 1) Réaliser une courte analyse exploratoire.\n",
    " 2) Tester différents modèles de prédiction afin de répondre au mieux à la problématique.\n",
    "\n",
    "Avant de quitter la salle de brief, Douglas, le project lead, vous donne quelques pistes et erreurs à éviter :\n",
    "\n",
    "> Douglas : L’objectif est de te passer des relevés de consommation annuels futurs (attention à la fuite de données). Nous ferons de toute façon pour tout nouveau bâtiment un premier relevé de référence la première année, donc rien ne t'interdit d’en déduire des variables structurelles aux bâtiments, par exemple la nature et proportions des sources d’énergie utilisées.. \n",
    "Fais bien attention au traitement des différentes variables, à la fois pour trouver de nouvelles informations (peut-on déduire des choses intéressantes d’une simple adresse ?) et optimiser les performances en appliquant des transformations simples aux variables (normalisation, passage au log, etc.).\n",
    "Mets en place une évaluation rigoureuse des performances de la régression, et optimise les hyperparamètres et le choix d’algorithmes de ML à l’aide d’une validation croisée.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_list = (\"pandas\", \"numpy\", \"matplotlib\", \"seaborn\", \"scikit-learn\", \"mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n"
     ]
    }
   ],
   "source": [
    "!python3 -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matplotlib==3.8.2',\n",
       " 'matplotlib-inline==0.1.6',\n",
       " 'mlflow==2.11.3',\n",
       " 'numpy @ file:///Users/runner/miniforge3/conda-bld/numpy_1704280780572/work/dist/numpy-1.26.3-cp310-cp310-macosx_11_0_arm64.whl#sha256=f96d0b051b72345dbc317d793b2b34c7c4b7f41b0b791ffc93e820c45ba6a91c',\n",
       " 'pandas==2.2.0',\n",
       " 'scikit-learn==1.4.0',\n",
       " 'seaborn==0.13.2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = !python3 -m pip freeze\n",
    "check = lambda i: any([(pack in i) for pack in package_list])\n",
    "txt = [i for i in txt if check(i)]\n",
    "txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built in\n",
    "import os, warnings\n",
    "import time\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# estimators\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, Perceptron\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## mlflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# exceptions\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# pipeline et preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Graphics and option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings('ignore)\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='_distutils_hack')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='importlib')\n",
    "\n",
    "# Ignore ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "We disable the warnings.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./data/cleaned/\"\n",
    "filename=\"df_SiteEnergyUseWN_0.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>GroupedPrimaryPropertyTypes</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>DistanceToDowntown</th>\n",
       "      <th>Log_SiteEnergyUseWN(kBtu)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>Bâtiments d'Hébergement</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>88434.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.864611</td>\n",
       "      <td>15.824652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>Bâtiments d'Hébergement</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>88502.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.907278</td>\n",
       "      <td>15.974742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>Bâtiments d'Hébergement</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>759392.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.047606</td>\n",
       "      <td>18.118725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>Bâtiments d'Hébergement</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>61320.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.038057</td>\n",
       "      <td>15.753792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>Bâtiments d'Hébergement</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>113580.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.100255</td>\n",
       "      <td>16.500395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Neighborhood GroupedPrimaryPropertyTypes  YearBuilt  NumberofBuildings  \\\n",
       "0     DOWNTOWN     Bâtiments d'Hébergement     1927.0                1.0   \n",
       "1     DOWNTOWN     Bâtiments d'Hébergement     1996.0                1.0   \n",
       "2     DOWNTOWN     Bâtiments d'Hébergement     1969.0                1.0   \n",
       "3     DOWNTOWN     Bâtiments d'Hébergement     1926.0                1.0   \n",
       "4     DOWNTOWN     Bâtiments d'Hébergement     1980.0                1.0   \n",
       "\n",
       "   NumberofFloors  PropertyGFABuilding(s)  ENERGYSTARScore  \\\n",
       "0            12.0                 88434.0             60.0   \n",
       "1            11.0                 88502.0             61.0   \n",
       "2            41.0                759392.0             43.0   \n",
       "3            10.0                 61320.0             56.0   \n",
       "4            18.0                113580.0             75.0   \n",
       "\n",
       "   DistanceToDowntown  Log_SiteEnergyUseWN(kBtu)  \n",
       "0            0.864611                  15.824652  \n",
       "1            0.907278                  15.974742  \n",
       "2            1.047606                  18.118725  \n",
       "3            1.038057                  15.753792  \n",
       "4            1.100255                  16.500395  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path+filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1379 entries, 0 to 1378\n",
      "Data columns (total 9 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Neighborhood                 1379 non-null   object \n",
      " 1   GroupedPrimaryPropertyTypes  1379 non-null   object \n",
      " 2   YearBuilt                    1379 non-null   float64\n",
      " 3   NumberofBuildings            1379 non-null   float64\n",
      " 4   NumberofFloors               1379 non-null   float64\n",
      " 5   PropertyGFABuilding(s)       1379 non-null   float64\n",
      " 6   ENERGYSTARScore              924 non-null    float64\n",
      " 7   DistanceToDowntown           1379 non-null   float64\n",
      " 8   Log_SiteEnergyUseWN(kBtu)    1379 non-null   float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 97.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_original=\"./data/source/\"\n",
    "filename_original=\"2016_Building_Energy_Benchmarking.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(path_original+filename_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3376 entries, 0 to 3375\n",
      "Data columns (total 46 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   OSEBuildingID                    3376 non-null   int64  \n",
      " 1   DataYear                         3376 non-null   int64  \n",
      " 2   BuildingType                     3376 non-null   object \n",
      " 3   PrimaryPropertyType              3376 non-null   object \n",
      " 4   PropertyName                     3376 non-null   object \n",
      " 5   Address                          3376 non-null   object \n",
      " 6   City                             3376 non-null   object \n",
      " 7   State                            3376 non-null   object \n",
      " 8   ZipCode                          3360 non-null   float64\n",
      " 9   TaxParcelIdentificationNumber    3376 non-null   object \n",
      " 10  CouncilDistrictCode              3376 non-null   int64  \n",
      " 11  Neighborhood                     3376 non-null   object \n",
      " 12  Latitude                         3376 non-null   float64\n",
      " 13  Longitude                        3376 non-null   float64\n",
      " 14  YearBuilt                        3376 non-null   int64  \n",
      " 15  NumberofBuildings                3368 non-null   float64\n",
      " 16  NumberofFloors                   3376 non-null   int64  \n",
      " 17  PropertyGFATotal                 3376 non-null   int64  \n",
      " 18  PropertyGFAParking               3376 non-null   int64  \n",
      " 19  PropertyGFABuilding(s)           3376 non-null   int64  \n",
      " 20  ListOfAllPropertyUseTypes        3367 non-null   object \n",
      " 21  LargestPropertyUseType           3356 non-null   object \n",
      " 22  LargestPropertyUseTypeGFA        3356 non-null   float64\n",
      " 23  SecondLargestPropertyUseType     1679 non-null   object \n",
      " 24  SecondLargestPropertyUseTypeGFA  1679 non-null   float64\n",
      " 25  ThirdLargestPropertyUseType      596 non-null    object \n",
      " 26  ThirdLargestPropertyUseTypeGFA   596 non-null    float64\n",
      " 27  YearsENERGYSTARCertified         119 non-null    object \n",
      " 28  ENERGYSTARScore                  2533 non-null   float64\n",
      " 29  SiteEUI(kBtu/sf)                 3369 non-null   float64\n",
      " 30  SiteEUIWN(kBtu/sf)               3370 non-null   float64\n",
      " 31  SourceEUI(kBtu/sf)               3367 non-null   float64\n",
      " 32  SourceEUIWN(kBtu/sf)             3367 non-null   float64\n",
      " 33  SiteEnergyUse(kBtu)              3371 non-null   float64\n",
      " 34  SiteEnergyUseWN(kBtu)            3370 non-null   float64\n",
      " 35  SteamUse(kBtu)                   3367 non-null   float64\n",
      " 36  Electricity(kWh)                 3367 non-null   float64\n",
      " 37  Electricity(kBtu)                3367 non-null   float64\n",
      " 38  NaturalGas(therms)               3367 non-null   float64\n",
      " 39  NaturalGas(kBtu)                 3367 non-null   float64\n",
      " 40  DefaultData                      3376 non-null   bool   \n",
      " 41  Comments                         0 non-null      float64\n",
      " 42  ComplianceStatus                 3376 non-null   object \n",
      " 43  Outlier                          32 non-null     object \n",
      " 44  TotalGHGEmissions                3367 non-null   float64\n",
      " 45  GHGEmissionsIntensity            3367 non-null   float64\n",
      "dtypes: bool(1), float64(22), int64(8), object(15)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_original.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1376 entries, 0 to 1378\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Neighborhood                 1376 non-null   object \n",
      " 1   GroupedPrimaryPropertyTypes  1376 non-null   object \n",
      " 2   YearBuilt                    1376 non-null   float64\n",
      " 3   NumberofBuildings            1376 non-null   float64\n",
      " 4   NumberofFloors               1376 non-null   float64\n",
      " 5   PropertyGFABuilding(s)       1376 non-null   float64\n",
      " 6   ENERGYSTARScore              922 non-null    float64\n",
      " 7   DistanceToDowntown           1376 non-null   float64\n",
      " 8   Log_SiteEnergyUseWN(kBtu)    1376 non-null   float64\n",
      " 9   EnergyUseQuartiles           1376 non-null   float64\n",
      "dtypes: float64(8), object(2)\n",
      "memory usage: 118.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Creating quartiles in df_original\n",
    "df_original['EnergyUseQuartiles'] = pd.qcut(df_original['SiteEUIWN(kBtu/sf)'], q=10, labels=False)\n",
    "\n",
    "# Merging the quartile information with df\n",
    "# Make sure df_original and df are aligned (you might need to merge based on a shared identifier if not)\n",
    "# For this example, I'm assuming they're aligned based on the index\n",
    "df['EnergyUseQuartiles'] = df_original['EnergyUseQuartiles']\n",
    "\n",
    "df = df.dropna(subset=['EnergyUseQuartiles'])\n",
    "df.info()\n",
    "\n",
    "# Preparing for the stratified split\n",
    "X = df.drop(columns=['Log_SiteEnergyUseWN(kBtu)', 'EnergyUseQuartiles'])  # Drop the target and quartile columns\n",
    "y = df['Log_SiteEnergyUseWN(kBtu)']  # Replace this with the name of your actual target variable\n",
    "stratify_col = df['EnergyUseQuartiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15.824652\n",
       "1    15.974742\n",
       "2    18.118725\n",
       "3    15.753792\n",
       "4    16.500395\n",
       "Name: Log_SiteEnergyUseWN(kBtu), dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1376 entries, 0 to 1378\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Neighborhood                 1376 non-null   object \n",
      " 1   GroupedPrimaryPropertyTypes  1376 non-null   object \n",
      " 2   YearBuilt                    1376 non-null   float64\n",
      " 3   NumberofBuildings            1376 non-null   float64\n",
      " 4   NumberofFloors               1376 non-null   float64\n",
      " 5   PropertyGFABuilding(s)       1376 non-null   float64\n",
      " 6   ENERGYSTARScore              922 non-null    float64\n",
      " 7   DistanceToDowntown           1376 non-null   float64\n",
      " 8   Log_SiteEnergyUseWN(kBtu)    1376 non-null   float64\n",
      " 9   EnergyUseQuartiles           1376 non-null   float64\n",
      "dtypes: float64(8), object(2)\n",
      "memory usage: 118.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MLflow experiment\n",
    "mlflow.set_experiment('Gradient_Boosting_Energy_stratify')\n",
    "\n",
    "# Define the Gradient Boosting parameters\n",
    "gb_params = {'n_estimators': 150, 'learning_rate': 0.1, \n",
    "             'max_depth': 2, 'min_samples_split': 20, \n",
    "             'min_samples_leaf': 10, 'max_features': 0.75}\n",
    "\n",
    "# Results DataFrame\n",
    "results = pd.DataFrame(columns=['Train R2', 'Test R2', 'Train MSE', 'Test MSE'])\n",
    "\n",
    "# Perform multiple train-test splits\n",
    "for split in range(50):\n",
    "    # Stratified train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=stratify_col)\n",
    "\n",
    "    # Preprocessing pipelines for numeric and categorical data\n",
    "    numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    pipe_trans_num = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    pipe_trans_cat = Pipeline(steps=[('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', pipe_trans_num, numeric_features),\n",
    "            ('cat', pipe_trans_cat, categorical_features)\n",
    "        ])\n",
    "\n",
    "    # Complete pipeline\n",
    "    k_val = 15\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"imputer\", KNNImputer(n_neighbors=k_val)),\n",
    "        (\"model\", GradientBoostingRegressor(**gb_params))\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Train the pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_train_pred = pipeline.predict(X_train)\n",
    "        y_test_pred = pipeline.predict(X_test)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "        # Log parameters, metrics, and model\n",
    "        mlflow.log_params(gb_params)\n",
    "        mlflow.log_metric('Train R2', train_r2)\n",
    "        mlflow.log_metric('Test R2', test_r2)\n",
    "        mlflow.log_metric('Train MSE', train_mse)\n",
    "        mlflow.log_metric('Test MSE', test_mse)\n",
    "        mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "\n",
    "        # Store results\n",
    "        results.loc[split] = [train_r2, test_r2, train_mse, test_mse]\n",
    "\n",
    "# Save results to CSV\n",
    "results.to_csv('gradient_boosting_energy_results_stratify.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MLflow experiment\n",
    "mlflow.set_experiment('Gradient_Boosting_Energy_no_stratify')\n",
    "\n",
    "# Define the Gradient Boosting parameters\n",
    "gb_params = {'n_estimators': 150, 'learning_rate': 0.1, \n",
    "             'max_depth': 2, 'min_samples_split': 20, \n",
    "             'min_samples_leaf': 10, 'max_features': 0.75}\n",
    "\n",
    "# Results DataFrame\n",
    "results = pd.DataFrame(columns=['Train R2', 'Test R2', 'Train MSE', 'Test MSE'])\n",
    "\n",
    "# Perform multiple train-test splits\n",
    "for split in range(50):\n",
    "    # Stratified train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Preprocessing pipelines for numeric and categorical data\n",
    "    numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    pipe_trans_num = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    pipe_trans_cat = Pipeline(steps=[('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', pipe_trans_num, numeric_features),\n",
    "            ('cat', pipe_trans_cat, categorical_features)\n",
    "        ])\n",
    "\n",
    "    # Complete pipeline\n",
    "    k_val = 15\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"imputer\", KNNImputer(n_neighbors=k_val)),\n",
    "        (\"model\", GradientBoostingRegressor(**gb_params))\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Train the pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_train_pred = pipeline.predict(X_train)\n",
    "        y_test_pred = pipeline.predict(X_test)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "        # Log parameters, metrics, and model\n",
    "        mlflow.log_params(gb_params)\n",
    "        mlflow.log_metric('Train R2', train_r2)\n",
    "        mlflow.log_metric('Test R2', test_r2)\n",
    "        mlflow.log_metric('Train MSE', train_mse)\n",
    "        mlflow.log_metric('Test MSE', test_mse)\n",
    "        mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "\n",
    "        # Store results\n",
    "        results.loc[split] = [train_r2, test_r2, train_mse, test_mse]\n",
    "\n",
    "# Save results to CSV\n",
    "results.to_csv('gradient_boosting_energy_results_no_stratify.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Relative Error, Mean Scores, Standard Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour le fichier avec stratification :\n",
      "Moyenne de Train R2: 0.8150219277377845\n",
      "Écart type de Train R2: 0.0059538721382647875\n",
      "Moyenne de Test R2: 0.7629904790917584\n",
      "Écart type de Test R2: 0.026435842940974442\n",
      "\n",
      "Pour le fichier sans stratification :\n",
      "Moyenne de Train R2: 0.8169128570150683\n",
      "Écart type de Train R2: 0.005010365802710162\n",
      "Moyenne de Test R2: 0.7548398801785892\n",
      "Écart type de Test R2: 0.024636238132332483\n"
     ]
    }
   ],
   "source": [
    "# Charger le premier fichier CSV\n",
    "file_path_stratify = \"gradient_boosting_energy_results_stratify.csv\"\n",
    "data_stratify = pd.read_csv(file_path_stratify)\n",
    "\n",
    "# Calculer la moyenne et l'écart type pour Train R2 et Test R2 du premier fichier\n",
    "mean_train_r2_stratify = data_stratify['Train R2'].mean()\n",
    "std_train_r2_stratify = data_stratify['Train R2'].std()\n",
    "mean_test_r2_stratify = data_stratify['Test R2'].mean()\n",
    "std_test_r2_stratify = data_stratify['Test R2'].std()\n",
    "\n",
    "# Charger le deuxième fichier CSV\n",
    "file_path_no_stratify = \"gradient_boosting_energy_results_no_stratify.csv\"\n",
    "data_no_stratify = pd.read_csv(file_path_no_stratify)\n",
    "\n",
    "# Calculer la moyenne et l'écart type pour Train R2 et Test R2 du deuxième fichier\n",
    "mean_train_r2_no_stratify = data_no_stratify['Train R2'].mean()\n",
    "std_train_r2_no_stratify = data_no_stratify['Train R2'].std()\n",
    "mean_test_r2_no_stratify = data_no_stratify['Test R2'].mean()\n",
    "std_test_r2_no_stratify = data_no_stratify['Test R2'].std()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Pour le fichier avec stratification :\")\n",
    "print(\"Moyenne de Train R2:\", mean_train_r2_stratify)\n",
    "print(\"Écart type de Train R2:\", std_train_r2_stratify)\n",
    "print(\"Moyenne de Test R2:\", mean_test_r2_stratify)\n",
    "print(\"Écart type de Test R2:\", std_test_r2_stratify)\n",
    "\n",
    "print(\"\\nPour le fichier sans stratification :\")\n",
    "print(\"Moyenne de Train R2:\", mean_train_r2_no_stratify)\n",
    "print(\"Écart type de Train R2:\", std_train_r2_no_stratify)\n",
    "print(\"Moyenne de Test R2:\", mean_test_r2_no_stratify)\n",
    "print(\"Écart type de Test R2:\", std_test_r2_no_stratify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour le fichier avec stratification :\n",
      "Moyenne de l'erreur R2 (%): 6.585013857322187\n",
      "\n",
      "Pour le fichier sans stratification :\n",
      "Moyenne de l'erreur R2 (%): 7.584748027027855\n"
     ]
    }
   ],
   "source": [
    "def pourcentage_erreur_R2(R2_train, R2_test):\n",
    "    erreur = abs(R2_train - R2_test) / R2_train\n",
    "    pourcentage_erreur = erreur * 100\n",
    "    return pourcentage_erreur\n",
    "\n",
    "# Charger le premier fichier CSV\n",
    "file_path_stratify = \"gradient_boosting_energy_results_stratify.csv\"\n",
    "data_stratify = pd.read_csv(file_path_stratify)\n",
    "\n",
    "# Calculer le pourcentage d'erreur pour chaque ligne dans le premier fichier\n",
    "data_stratify['Erreur R2 (%)'] = pourcentage_erreur_R2(data_stratify['Train R2'], data_stratify['Test R2'])\n",
    "\n",
    "# Calculer la moyenne de l'erreur\n",
    "mean_erreur_stratify = data_stratify['Erreur R2 (%)'].mean()\n",
    "\n",
    "# Charger le deuxième fichier CSV\n",
    "file_path_no_stratify = \"gradient_boosting_energy_results_no_stratify.csv\"\n",
    "data_no_stratify = pd.read_csv(file_path_no_stratify)\n",
    "\n",
    "# Calculer le pourcentage d'erreur pour chaque ligne dans le deuxième fichier\n",
    "data_no_stratify['Erreur R2 (%)'] = pourcentage_erreur_R2(data_no_stratify['Train R2'], data_no_stratify['Test R2'])\n",
    "\n",
    "# Calculer la moyenne de l'erreur\n",
    "mean_erreur_no_stratify = data_no_stratify['Erreur R2 (%)'].mean()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Pour le fichier avec stratification :\")\n",
    "print(\"Moyenne de l'erreur R2 (%):\", mean_erreur_stratify)\n",
    "\n",
    "print(\"\\nPour le fichier sans stratification :\")\n",
    "print(\"Moyenne de l'erreur R2 (%):\", mean_erreur_no_stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
